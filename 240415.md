# 🥰250415 나만의 LLM 스터디 발표


## 1.목표 LLM
향상된 한국어 figurative language 이해를 가진 LLM (Kofig-LLM)

## 2. 필요 데이터셋
1) 한국어 figuartive language 이해 관련 데이터셋
  - EN FLUTE 데이터셋 [Chakrabarty et al., 2022](https://arxiv.org/abs/2205.12404) KO 번역본 보유
     - FLUTE datset: 직유, 은유, 관용표현, 비꼬기 문장-일반 문장 쌍으로 이루어진 NLI 데이터셋
  - 실제 언어 생활에서 쓰이는 figurative language 사용 사례
     - 가장 바람직하게는 대화 데이터셋이 최적이나, 구하지 못할 가능성 존재
     - 국립국어원 사전 예문, 문학 말뭉치 등에서 수집 필요

 2) LLM 학습을 위한 instruction 데이터셋 형태 모색
    - 인스트럭션 데이터셋 형태: LIMA dataset 등 유명 데이터셋 형태 확인
    - [Awesome instruction dataset](https://github.com/jianzhnie/awesome-instruction-datasets)


## 3. 학습 모델 
● 한국어 튜닝이 된 LLM 우선
  - 선험적으로 3B 미만의 sLLM은 한국어 이해 성능이 좋지 않음
  - 실습 환경(코랩, 기타 GPU 대여)에서 구동 가능한 7-8B LLM 중 한국어 fine-tuning 모델 사용 예정
  - [LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct](https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct)
  - [Bllossom/llama-3.2-Korean-Bllossom-AICA-5B](https://huggingface.co/Bllossom/llama-3.2-Korean-Bllossom-AICA-5B)
